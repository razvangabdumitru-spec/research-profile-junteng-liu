# Junteng Liu — Research Profile

First-year PhD candidate, HKUST NLP Group

Overview

Junteng Liu is a PhD student in Computer Science at the Hong Kong University of Science and Technology (HKUST), advised by Prof. Junxian He. His research focuses on natural language processing and machine learning, with particular interests in LLM reasoning, reinforcement learning, hallucination in vision-language models, and model interpretability and truthfulness.

Selected Highlights

- First author on EMNLP 2024 paper: "On the Universal Truthfulness Hyperplane Inside LLMs" (Shiqi Chen, Yu Cheng, Junxian He)
- First author on ArXiv (2025): "SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning Logical Reasoning and Beyond" (code available)
- First author on ArXiv (2025): "On the Perception Bottleneck of VLMs for Chart Understanding" (Vision4Chart repo)
- Co-author on ICML 2024: "In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation"
- Co-author on NeurIPS 2023: "C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models"
- Co-author on NeurIPS 2023: "Composing Parameter-Efficient Modules with Arithmetic Operations"

Key Skills & Expertise

- Large Language Models (LLMs) — reasoning, truthfulness, interpretability
- Vision-Language Models (VLMs) — chart/visual understanding and hallucination analysis
- Reinforcement Learning applied to LLM behaviors
- Synthetic data generation for logical reasoning and model evaluation
- ML tooling and reproducible research (code repos linked to publications)

Research Positions

- PhD candidate, Hong Kong University of Science and Technology (HKUST) — HKUST NLP Group (2024–present)
- Research Intern, MINIMAX (Feb 2025–present)
- Research Intern, Tencent WXG (June–Sept 2024)
- Research Intern, Shanghai AI Lab (June–Dec 2023)

Selected Publications & Links

- "On the Universal Truthfulness Hyperplane Inside LLMs", EMNLP 2024 — (first author) — GitHub: Universal_Truthfulness_Hyperplane
- "SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning Logical Reasoning and Beyond", 2025 — (first author) — GitHub: SynLogic
- "On the Perception Bottleneck of VLMs for Chart Understanding", 2025 — (first author) — GitHub: Vision4Chart
- "In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation", ICML 2024 — (co-author)
- "C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models", NeurIPS 2023 — (co-author)
- "Composing Parameter-Efficient Modules with Arithmetic Operations", NeurIPS 2023 — (co-author)

Awards & Honors

- Zhiyuan Honor Scholarship (Shanghai Jiao Tong University)

Contact

- Email: jliugi@connect.ust.hk
- GitHub: https://github.com/Vicent0205
- Google Scholar: https://scholar.google.com/citations?hl=en&user=tbK9jl4AAAAJ&view_op=list_works&sortby=pubdate
- X: @junteng88716710

Suggested improvements (tracked as issues)

See ISSUES.md for a starter list.
